# 통계학 6주차 정규과제

📌통계학 정규과제는 매주 정해진 분량의 『*데이터 분석가가 반드시 알아야 할 모든 것*』 을 읽고 학습하는 것입니다. 이번 주는 아래의 **Statistics_6th_TIL**에 나열된 분량을 읽고 `학습 목표`에 맞게 공부하시면 됩니다.

아래의 문제를 풀어보며 학습 내용을 점검하세요. 문제를 해결하는 과정에서 개념을 스스로 정리하고, 필요한 경우 추가자료와 교재를 다시 참고하여 보완하는 것이 좋습니다.

6주차는 `3부. 데이터 분석하기`를 읽고 새롭게 배운 내용을 정리해주시면 됩니다.


## Statistics_6th_TIL

### 3부. 데이터 분석하기
### 12.통계 기반 분석 방법론



## Study Schedule

|주차 | 공부 범위     | 완료 여부 |
|----|----------------|----------|
|1주차| 1부 p.2~56     | ✅      |
|2주차| 1부 p.57~79    | ✅      | 
|3주차| 2부 p.82~120   | ✅      | 
|4주차| 2부 p.121~202  | ✅      | 
|5주차| 2부 p.203~254  | ✅      | 
|6주차| 3부 p.300~356  | ✅      | 
|7주차| 3부 p.357~615  | 🍽️      |


# 12. 통계 기반 분석 방법론 (모르는 내용 위주로)


### 🔎 잠재요인 (Latent Factor)
- 잠재요인은 직접 관찰할 수 없는 특성이나 속성  

- 데이터에서 직접 측정할 수 없지만, 여러 관찰된 변수들에 영향을 미치는 **숨겨진 변수**라고 볼 수 있음

#### 📝 예시
고객 만족도 조사:

여러 질문 (서비스 품질, 가격 만족도, 응답 속도, 직원의 친절함 등) → **고객 만족도**라는 잠재요인

심리 검사:

여러 항목 (짜증, 긴장, 불면증) → **불안**이라는 잠재요인



### **🔎 요인분석 (Factor Analysis)**

- 요인분석은 여러 변수들 사이의 복잡한 상관관계를 단순화하여 **잠재 요인 (latent factors)**을 찾아내는 기법  

---

#### **📝 EFA (탐색적 요인분석, Exploratory Factor Analysis)**

- **목적:** 데이터에 숨겨진 잠재 요인을 **탐색**하는 것이 목표 

- **방식:** 어떤 요인들이 존재할지 미리 가정하지 않고, 데이터를 통해 요인을 찾아냄 
- **특징:** 데이터의 구조를 밝히는 데 초점이 맞춰져 있음

- **데이터의 구조**를 밝힌다는 것은, 여러 변수들이 어떻게 **잠재 요인**으로 묶일 수 있는지를 파악하는 것을 의미

- **예시:** 설문조사에서 여러 문항을 요약하여 몇 개의 요인으로 줄이고 싶을 때 사용  

---

#### **📝 CFA (확인적 요인분석, Confirmatory Factor Analysis)**

- **목적:** 이미 가정한 요인 구조가 실제 데이터에 얼마나 적합한지를 **확인**하는 것

- **방식:** 미리 정의된 요인 구조를 검증하는 데 사용됨

- **특징:** 이론적인 모델이 있는 상태에서 요인 구조의 타당성을 검증

- **예시:** 심리검사의 신뢰도를 평가하거나, 마케팅에서 고객의 만족도를 요인으로 검증할 때 사용



---

#### **📝 KMO 검정 (Kaiser-Meyer-Olkin Test)**

- **목적:** 요인분석을 수행하기 전에 데이터가 요인분석에 적합한지를 판단하기 위한 테스트 

- **방식:** 변수들 간의 상관관계가 얼마나 강한지를 평가  

- **결과 해석:**  
    - **0.8~1.0:** 아주 좋음  
    - **0.7~0.8:** 양호함  
    - **0.6~0.7:** 보통  
    - **0.5~0.6:** 나쁨  
    - **0.5 미만:** 요인분석 부적합  

---

#### **📝 바틀렛 구형성 검정 (Bartlett's Test of Sphericity)**

- **목적:** 데이터가 요인분석에 적합한지 확인하는 또 다른 방법 

- **방식:** 변수들 사이의 상관관계가 통계적으로 유의미한지 검증  

- **결과 해석:** p-value가 **0.05 미만**이면 요인분석에 적합함 (귀무가설 기각)

- **귀무가설 (H0):** 상관행렬이 단위행렬 (Identity Matrix)이다

- **대립가설 (H1):** 상관행렬이 단위행렬이 아니다


---

#### **💡 요약**

- **EFA:** 탐색용, 요인 구조를 발견하기 위해 사용  
- **CFA:** 검증용, 미리 가정한 요인 구조의 타당성을 평가  
- **KMO 검정:** 데이터가 요인분석에 적합한지 평가  
- **바틀렛 검정:** 상관행렬의 의미를 검증  

---

#### **🔎 단순히 상관계수와 VIF만으로 충분하지 않은 이유**

1. **상관계수와 VIF의 한계**  
    - 상관계수는 변수 간의 단순 선형 관계만 측정함

    - 다변량 관계를 고려하지 않기 때문에 숨겨진 요인을 발견하기 어려움

    - 상관계수가 낮다고 해서 항상 독립적인 것은 아님 (비선형 관계 가능)

    - VIF는 다중공선성 문제만 해결할 수 있음

    - 변수들이 잠재적으로 묶여 있는지를 파악하기 어려움


2. **잠재 요인 (Latent Factor) 발견**  

    - 요인분석의 핵심은 여러 변수가 하나의 **잠재 요인**에 의해 설명될 수 있는지를 찾는 것임

    - **예시:** 설문조사에서 '만족도'라는 잠재 요인을 구성하는 여러 문항이 있을 수 있음 (서비스 품질, 가격, 응답 속도 등)


3. **데이터의 구조적 이해**  
    - 상관계수와 VIF는 단변량적으로 상관관계를 평가하지만, 요인분석은 다변량적 관계를 탐색함

    - **EFA:** 데이터가 어떻게 그룹으로 묶일 수 있는지를 탐색하는 데 사용

    - **CFA:** 이미 정의된 요인 구조가 실제 데이터에 적합한지를 확인하는 데 사용


4. **해석 가능성의 향상**  
    - 단순한 상관관계보다 더 깊은 이해를 제공함 

    - 요인분석을 통해 복잡한 데이터를 더 간단하고 의미 있는 요인으로 요약할 수 있음

    - **예시:** 심리검사에서 여러 항목이 '불안'이나 '자신감' 같은 요인으로 묶일 수 있음


5. **데이터 축소 (Dimensionality Reduction)**  
    - 차원 축소: 요인분석은 PCA와 달리 **해석 가능성**을 유지하면서 변수를 줄일 수 있음

    - **예시:** 고객 만족도 조사의 50개 문항을 3~5개의 요인으로 축소하여 데이터의 복잡성을 줄일 수 있음



 **EFA (탐색적 요인분석)** 와 **CFA (확인적 요인분석)** 는 상호 배타적인 기법이 아니며, 연속적인 분석 과정의 일부로 함께 사용될 수 있음

---

## 12.4 다중공선성 해결과 섀플리 분석  

- 다중공선성 : 독립변수들 간의 상관관계가 높은 현상  

- 즉, 두 개 이상의 독립변수가 서로 선형적인 관계를 나타낼 때 다중공선성이 있다고 함 

- 회귀분석에서는 독립변수들 간에 서로 독립이라는 가정을 하기 때문에 다중공선성이 발생한다면 이 가정을 위반하는 것  



### **🔎 결정계수 (R²)**

- 결정계수는 **모델 전체의 설명력**을 나타내는 지표

- 개별 변수마다 있는 것이 아니라, **하나의 모델**에 대해 **단 하나의 R²**만 존재  


- **잔차의 합을 기준으로 계산**  

- R²는 모델의 잔차를 기준으로 계산되며, 모델 전체의 성능을 평가하는 지표이기 때문에 개별 변수별로 나눠 계산하지 않음  


## 다중공선성을 판별하는 몇 가지 기준 

1. 상관분석을 통해 독립 변수 간의 상관계수 확인 

- 상관계수의 절대치가 0.7 이상이면 두 변수 간의 상관성이 높다는 것!

-  다중공선성이 나타날 것을 의심할 수 있음  그러나 이 방법은 변수가 많을 경우 파악이 힘듬  

2. 회귀분석 결과에서 R² 값은 크지만 회귀계수에 대한 t값이 낮다면 다중공선성 의심  

- 종속변수에 대한 독립변수들의 설명력이 높지만 각 계수 추정치의 표준오차가 크다는 것은 독립변수 간에 상관성이 크다는 것을 의미  



3. VIF를 통해 다중공선성 판단  

- VIF 값은 회귀분석 모델에 사용된 다른 독립 변수들이 해당 변수 대신 모델을 설명해 줄 수 있는 정도를 나타냄  

- 다시 말해 해당 변수가 다른 변수들에 의해 설명될 수 있는 정도를 의미  

- 일반적으로 5 이상이면 다중공선성을 의심해야 하고 10 이상일 경우 다중공선성이 있다고 판단  

## 다중공선성을 해결하기 위한 방법 

1. VIF 값이 높은 변수들 중에서 종속변수와의 상관성(설명력)이 가장 낮은 변수를 제거하고 다시 VIF값을 확인하는 것을 반복하는 것  

- 이 때 유의할 점은, 특정 변수가 제거 대상이 됐다고 해도 분석 모델의 이론이나 가설에 중요한 역할을 할 수도 있으므로 가설과 비즈니스적 요소도 함께 고려하여 변수를 제거해야 함  

2. 표본 관측치를 추가확보  

 - 분석 모수가 많아질수록 회귀계수의 분산과 표준오차가 감소. 하지만 이는 현실적으로 어려움 

3. 변수 가공 
- 로그변환, 표준화 및 정규화 변환 등 

- 연속형 변수를 구간화 혹은 명목변수로 변환 

4. 주성분 분석 
- 하지만 변수의 해석이 어려워짐

5. 변수 선택 알고리즘 

- 전진 선택법 (Forward selection)

- 후진 제거법 (Backward elimination)

- 단계적 선택법 (Stepwise method)

## 섀플리 밸류 (Shapley Value) 분석

- 로이드 섀플리가 개발한 독립변수의 설명력 분배방법  

- 섀플리 밸류는 모델에 투입했을 때 설명력에 어느 정도의 기여를 하는지 측정할 수 있는 기준값으로 활용할 수 있음  




# 확인 문제

### **문제 1.**
> **🧚 경희는 다트비 교육 연구소의 연구원이다. 경희는 이번에 새롭게 개발한 교육 프로그램이 기존 프로그램보다 학습 성취도 향상에 효과적인지 검증하고자 100명의 학생을 무작위로 두 그룹으로 나누어 한 그룹(A)은 새로운 교육 프로그램을, 다른 그룹(B)은 기존 교육 프로그램을 수강하도록 하였다. 실험을 시작하기 전, 두 그룹(A, B)의 초기 시험 점수 평균을 비교한 결과, 유의미한 차이가 없었다. 8주 후, 학생들의 최종 시험 점수를 수집하여 두 그룹 간 평균 점수를 비교하려고 한다.**   

> **🔍 Q1. 이 실험에서 사용할 적절한 검정 방법은 무엇인가요?**

```
t-검정 (모집단의 분산이 주어지지 않음)
```

> **🔍 Q2. 이 실험에서 설정해야 할 귀무가설과 대립가설을 각각 작성하세요.**

```
- 귀무가설 (H0): 새로운 교육 프로그램(A)과 기존 교육 프로그램(B)의 최종 시험 점수 평균이 동일하다.

- 대립가설 (H1): 새로운 교육 프로그램(A)과 기존 교육 프로그램(B)의 최종 시험 점수 평균이 다르다.

```

> **🔍 Q3. 검정을 수행하기 위한 절차를 순서대로 서술하세요.**

<!--P.337의 실습 코드 흐름을 확인하여 데이터를 불러온 후부터 어떤 절차로 검정을 수행해야 하는지 고민해보세요.-->

```
1. 데이터 수집: 각 그룹(A, B)의 최종 시험 점수를 수집

2. 기술 통계 계산: 각 그룹의 평균, 분산, 표준편차를 계산하여 점수 분포를 파악

3. 가정 검토:
   - 정규성 검정: 각 그룹의 점수가 정규 분포를 따르는지 확인 (Shapiro-Wilk 또는 Kolmogorov-Smirnov 검정 사용)

   - 등분산성 검정: 두 그룹의 점수 분산이 동일한지 확인 (Levene's test 또는 Bartlett's test 사용)

4. 독립표본 t-검정 수행:

   - 등분산을 가정하는 경우: Student's t-test (equal_var=True)

   - 등분산을 가정하지 않는 경우: Welch's t-test (equal_var=False)

5. p-value 확인:

   - 유의수준(α) 설정 (보통 0.05)
   - p-value가 α보다 작으면 귀무가설 기각

6. 결과 해석: 프로그램 간 성취도 차이가 있는지 결론을 도출

```

> **🔍 Q4. 이 검정을 수행할 때 가정해야 하는 통계적 조건을 설명하세요.**

```
1. 독립성 가정

2. 정규성 가정

3. 등분산성 가정
```

> **🔍 Q5. 추가적으로 최신 AI 기반 교육 프로그램(C)도 도입하여 기존 프로그램(B) 및 새로운 프로그램(A)과 비교하여 성취도 차이가 있는지 평가하고자 한다면 어떤 검정 방법을 사용해야 하나요? 단, 실험을 시작하기 전, C 그룹의 초기 점수 평균도 A, B 그룹과 유의미한 차이가 없었다고 가정한다.**

```
일원 분산분석 (One-Way ANOVA)
```

> **🔍 Q6. 5번에서 답한 검정을 수행한 결과, 유의미한 차이가 나타났다면 추가적으로 어떤 검정을 수행해 볼 수 있을까요?**

```
사후검정 (Post-Hoc Test)
```

---

### **문제 2. 카이제곱 검정**  
> **🧚 다음 중 어떠한 경우에 카이제곱 검정을 사용해야 하나요?   
1️⃣ 제품 A, B, C의 평균 매출 차이를 비교하고자 한다.  
2️⃣ 남성과 여성의 신체 건강 점수 평균 차이를 분석한다.  
3️⃣ 제품 구매 여부(구매/미구매)와 고객의 연령대(10대, 20대, 30대…) 간의 연관성을 분석한다.  
4️⃣ 특정 치료법이 환자의 혈압을 감소시키는 효과가 있는지 확인한다.**  

```
쌈번 
```

### 🎉 수고하셨습니다.

