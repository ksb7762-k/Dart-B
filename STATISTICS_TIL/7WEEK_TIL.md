# 12. 통계 기반 분석 방법론 (모르는 내용 위주로)


### 🔎 잠재요인 (Latent Factor)
- 잠재요인은 직접 관찰할 수 없는 특성이나 속성  

- 데이터에서 직접 측정할 수 없지만, 여러 관찰된 변수들에 영향을 미치는 **숨겨진 변수**라고 볼 수 있음

#### 📝 예시
고객 만족도 조사:

여러 질문 (서비스 품질, 가격 만족도, 응답 속도, 직원의 친절함 등) → **고객 만족도**라는 잠재요인

심리 검사:

여러 항목 (짜증, 긴장, 불면증) → **불안**이라는 잠재요인



### **🔎 요인분석 (Factor Analysis)**

- 요인분석은 여러 변수들 사이의 복잡한 상관관계를 단순화하여 **잠재 요인 (latent factors)**을 찾아내는 기법  

---

#### **📝 EFA (탐색적 요인분석, Exploratory Factor Analysis)**

- **목적:** 데이터에 숨겨진 잠재 요인을 **탐색**하는 것이 목표 

- **방식:** 어떤 요인들이 존재할지 미리 가정하지 않고, 데이터를 통해 요인을 찾아냄 
- **특징:** 데이터의 구조를 밝히는 데 초점이 맞춰져 있음

- **데이터의 구조**를 밝힌다는 것은, 여러 변수들이 어떻게 **잠재 요인**으로 묶일 수 있는지를 파악하는 것을 의미

- **예시:** 설문조사에서 여러 문항을 요약하여 몇 개의 요인으로 줄이고 싶을 때 사용  

---

#### **📝 CFA (확인적 요인분석, Confirmatory Factor Analysis)**

- **목적:** 이미 가정한 요인 구조가 실제 데이터에 얼마나 적합한지를 **확인**하는 것

- **방식:** 미리 정의된 요인 구조를 검증하는 데 사용됨

- **특징:** 이론적인 모델이 있는 상태에서 요인 구조의 타당성을 검증

- **예시:** 심리검사의 신뢰도를 평가하거나, 마케팅에서 고객의 만족도를 요인으로 검증할 때 사용



---

#### **📝 KMO 검정 (Kaiser-Meyer-Olkin Test)**

- **목적:** 요인분석을 수행하기 전에 데이터가 요인분석에 적합한지를 판단하기 위한 테스트 

- **방식:** 변수들 간의 상관관계가 얼마나 강한지를 평가  

- **결과 해석:**  
    - **0.8~1.0:** 아주 좋음  
    - **0.7~0.8:** 양호함  
    - **0.6~0.7:** 보통  
    - **0.5~0.6:** 나쁨  
    - **0.5 미만:** 요인분석 부적합  

---

#### **📝 바틀렛 구형성 검정 (Bartlett's Test of Sphericity)**

- **목적:** 데이터가 요인분석에 적합한지 확인하는 또 다른 방법 

- **방식:** 변수들 사이의 상관관계가 통계적으로 유의미한지 검증  

- **결과 해석:** p-value가 **0.05 미만**이면 요인분석에 적합함 (귀무가설 기각)

- **귀무가설 (H0):** 상관행렬이 단위행렬 (Identity Matrix)이다

- **대립가설 (H1):** 상관행렬이 단위행렬이 아니다


---

#### **💡 요약**

- **EFA:** 탐색용, 요인 구조를 발견하기 위해 사용  
- **CFA:** 검증용, 미리 가정한 요인 구조의 타당성을 평가  
- **KMO 검정:** 데이터가 요인분석에 적합한지 평가  
- **바틀렛 검정:** 상관행렬의 의미를 검증  

---

#### **🔎 단순히 상관계수와 VIF만으로 충분하지 않은 이유**

1. **상관계수와 VIF의 한계**  
    - 상관계수는 변수 간의 단순 선형 관계만 측정함

    - 다변량 관계를 고려하지 않기 때문에 숨겨진 요인을 발견하기 어려움

    - 상관계수가 낮다고 해서 항상 독립적인 것은 아님 (비선형 관계 가능)

    - VIF는 다중공선성 문제만 해결할 수 있음

    - 변수들이 잠재적으로 묶여 있는지를 파악하기 어려움


2. **잠재 요인 (Latent Factor) 발견**  

    - 요인분석의 핵심은 여러 변수가 하나의 **잠재 요인**에 의해 설명될 수 있는지를 찾는 것임

    - **예시:** 설문조사에서 '만족도'라는 잠재 요인을 구성하는 여러 문항이 있을 수 있음 (서비스 품질, 가격, 응답 속도 등)


3. **데이터의 구조적 이해**  
    - 상관계수와 VIF는 단변량적으로 상관관계를 평가하지만, 요인분석은 다변량적 관계를 탐색함

    - **EFA:** 데이터가 어떻게 그룹으로 묶일 수 있는지를 탐색하는 데 사용

    - **CFA:** 이미 정의된 요인 구조가 실제 데이터에 적합한지를 확인하는 데 사용


4. **해석 가능성의 향상**  
    - 단순한 상관관계보다 더 깊은 이해를 제공함 

    - 요인분석을 통해 복잡한 데이터를 더 간단하고 의미 있는 요인으로 요약할 수 있음

    - **예시:** 심리검사에서 여러 항목이 '불안'이나 '자신감' 같은 요인으로 묶일 수 있음


5. **데이터 축소 (Dimensionality Reduction)**  
    - 차원 축소: 요인분석은 PCA와 달리 **해석 가능성**을 유지하면서 변수를 줄일 수 있음

    - **예시:** 고객 만족도 조사의 50개 문항을 3~5개의 요인으로 축소하여 데이터의 복잡성을 줄일 수 있음



 **EFA (탐색적 요인분석)** 와 **CFA (확인적 요인분석)** 는 상호 배타적인 기법이 아니며, 연속적인 분석 과정의 일부로 함께 사용될 수 있음

---

## 12.4 다중공선성 해결과 섀플리 분석  

- 다중공선성 : 독립변수들 간의 상관관계가 높은 현상  

- 즉, 두 개 이상의 독립변수가 서로 선형적인 관계를 나타낼 때 다중공선성이 있다고 함 

- 회귀분석에서는 독립변수들 간에 서로 독립이라는 가정을 하기 때문에 다중공선성이 발생한다면 이 가정을 위반하는 것  



### **🔎 결정계수 (R²)**

- 결정계수는 **모델 전체의 설명력**을 나타내는 지표

- 개별 변수마다 있는 것이 아니라, **하나의 모델**에 대해 **단 하나의 R²**만 존재  


- **잔차의 합을 기준으로 계산**  

- R²는 모델의 잔차를 기준으로 계산되며, 모델 전체의 성능을 평가하는 지표이기 때문에 개별 변수별로 나눠 계산하지 않음  


## 다중공선성을 판별하는 몇 가지 기준 

1. 상관분석을 통해 독립 변수 간의 상관계수 확인 

- 상관계수의 절대치가 0.7 이상이면 두 변수 간의 상관성이 높다는 것!

-  다중공선성이 나타날 것을 의심할 수 있음  그러나 이 방법은 변수가 많을 경우 파악이 힘듬  

2. 회귀분석 결과에서 R² 값은 크지만 회귀계수에 대한 t값이 낮다면 다중공선성 의심  

- 종속변수에 대한 독립변수들의 설명력이 높지만 각 계수 추정치의 표준오차가 크다는 것은 독립변수 간에 상관성이 크다는 것을 의미  



3. VIF를 통해 다중공선성 판단  

- VIF 값은 회귀분석 모델에 사용된 다른 독립 변수들이 해당 변수 대신 모델을 설명해 줄 수 있는 정도를 나타냄  

- 다시 말해 해당 변수가 다른 변수들에 의해 설명될 수 있는 정도를 의미  

- 일반적으로 5 이상이면 다중공선성을 의심해야 하고 10 이상일 경우 다중공선성이 있다고 판단  

## 다중공선성을 해결하기 위한 방법 

1. VIF 값이 높은 변수들 중에서 종속변수와의 상관성(설명력)이 가장 낮은 변수를 제거하고 다시 VIF값을 확인하는 것을 반복하는 것  

- 이 때 유의할 점은, 특정 변수가 제거 대상이 됐다고 해도 분석 모델의 이론이나 가설에 중요한 역할을 할 수도 있으므로 가설과 비즈니스적 요소도 함께 고려하여 변수를 제거해야 함  

2. 표본 관측치를 추가확보  

 - 분석 모수가 많아질수록 회귀계수의 분산과 표준오차가 감소. 하지만 이는 현실적으로 어려움 

3. 변수 가공 
- 로그변환, 표준화 및 정규화 변환 등 

- 연속형 변수를 구간화 혹은 명목변수로 변환 

4. 주성분 분석 
- 하지만 변수의 해석이 어려워짐

5. 변수 선택 알고리즘 

- 전진 선택법 (Forward selection)

- 후진 제거법 (Backward elimination)

- 단계적 선택법 (Stepwise method)

## 섀플리 밸류 (Shapley Value) 분석

- 로이드 섀플리가 개발한 독립변수의 설명력 분배방법  

- 섀플리 밸류는 모델에 투입했을 때 설명력에 어느 정도의 기여를 하는지 측정할 수 있는 기준값으로 활용할 수 있음  





