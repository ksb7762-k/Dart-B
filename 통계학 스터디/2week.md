# 선택편향
관측 데이터를 선택하는 방식 때문에 생기는 편향 

### 데이터 스누핑(Data Snooping)

**데이터 스누핑**이란, 동일한 데이터를 반복적으로 사용하여 가설을 세우고 검증하는 과정에서 발생하는 **편향(Bias)**을 의미.  분석자가 데이터에서 우연히 발견한 패턴이나 관계를 마치 일반적인 규칙처럼 해석하여 모델을 만들면, 해당 모델은 실제 새로운 데이터에서는 성능이 떨어질 수 있음. 이는 모델의 **과적합(Overfitting)**을 유발하고, 분석 결과의 **신뢰도와 일반화 가능성**을 크게 해칠 수 있음.

- ✅ **문제점**: 검증에 사용된 데이터가 이미 가설 설정에 영향을 미쳤기 때문에 검증의 타당성이 떨어짐
- ✅ **예시**: 수많은 변수 조합을 시도하다 우연히 높은 상관관계를 발견하고 이를 근거로 가설을 세운 경우
- ✅ **해결 방법**: 
  - 데이터를 훈련용(train), 검증용(validation), 테스트용(test)으로 나누어 사용
  - 사전에 분석 계획(가설, 변수, 모델 등)을 명확히 세우고 따르기
  - 교차 검증(cross-validation) 등 객관적인 평가 방식 활용

데이터 스누핑을 방지하는 것은 **신뢰할 수 있는 데이터 분석**을 위한 중요한 전제


# 핵심은 "검증의 객관성"
데이터에서 나온 통찰이 유효할 수도 있지만, 그걸 검증하는 과정이 동일한 데이터에 의존하면 위험

마치 시험 문제를 미리 보고 공부한 사람이 시험을 잘 봤다고 해서, 그 사람이 실력이 있다고 보긴 어려운 것처럼!

그래서 좋은 접근은?
데이터에서 흥미로운 관계 발견 → "이게 일반적인 규칙일 수도 있겠네?"

→ 그 관계를 다른 데이터셋에서 검증하거나, 다시 수집한 데이터로 테스트

이 과정을 통해서야 "이건 진짜 일반적인 규칙이야"라고 말할 수 있음

### 홀드아웃 세트(Holdout Set)와 목표값(Target) 누수

데이터 분석이나 머신러닝에서 **홀드아웃 세트**는 모델의 일반화 성능을 평가하기 위해 훈련 과정에서 완전히 분리해 두는 **검증용 데이터셋** 
 하지만 이 홀드아웃 세트에 **목표값(Target)**이나 관련 정보가 누출되면, 모델은 미래 데이터를 "미리 본 것처럼" 행동하게 되어 **정확도가 부풀려지는 심각한 오류**가 발생  

#### ✅ 목표값 누수(Target Leakage) 예시
- 훈련 데이터에 **미래를 암시하는 변수**가 포함된 경우 (예: 고객 이탈 여부 예측에 '해지일'이 들어있는 경우)
- 피처 엔지니어링 과정에서 전체 데이터의 통계를 사용해 피처를 만든 경우 (예: 전체 평균을 기준으로 스케일링)
- **홀드아웃 세트를 피처 선택, 모델 튜닝, 하이퍼파라미터 조정 등에 활용한 경우**

#### ✅ 왜 문제인가?
- 검증 세트는 **진짜 새로운 데이터처럼 사용**되어야 하는데, 정보가 섞이면 **데이터 스누핑과 같은 오류** 발생
- 모델 성능이 실제보다 높게 나와서 **현실에서는 성능이 떨어질 가능성**이 큼

#### ✅ 방지 방법
- 데이터 분할(train/validation/test)은 **분석 초기**에 확실히 나눠두기    
- 피처 생성 및 전처리는 반드시 **훈련 데이터 기준**으로만 진행    
- 목표값과 관련된 정보가 피처에 직접 혹은 간접적으로 들어가지 않도록 주의    
  
**홀드아웃 세트는 절대 건드리지 않는 원칙**이 신뢰할 수 있는 모델링의 기본  
 

### 타겟 셔플링 (Target Shuffling, 순열 검정)

**타겟 셔플링**은 모델이 진짜로 의미 있는 패턴을 학습했는지를 확인하기 위해 사용하는 **검정 기법**  
 분석 대상 데이터의 **목표값(타겟)을 무작위로 섞어서 모델을 학습**한 뒤, 원래 모델과 비교해 성능 차이가 통계적으로 유의미한지를 평가  

#### ✅ 왜 쓰는가?  
- 모델이 높은 성능을 보일 때, **우연히 그런 건지** 아니면 **진짜 의미 있는 패턴을 학습한 건지** 확인하기 위해  
- **데이터 스누핑**이나 **과적합** 여부를 간접적으로 점검할 수 있음  

#### ✅ 방법 요약  
1. 원래 데이터로 모델 학습 → 성능 기록 (예: AUC = 0.85)  
2. 타겟 값을 여러 번 무작위로 섞고 각 경우마다 모델 재학습 → 성능 기록 (예: AUC 평균 = 0.52)
3. 원래 성능이 셔플된 성능 분포에서 **상위 몇 %에 해당하는지(p-value)** 평가  

#### ✅ 해석
- 만약 셔플된 성능 분포와 원래 성능 차이가 크면 → **모델이 진짜 패턴을 학습한 것**  
- 반대로 성능 차이가 작거나 비슷하면 → **우연한 결과일 가능성**  

> ✔️ **타겟 셔플링은 누수를 유발하는 게 아니라, 오히려 누수나 과적합 여부를 점검할 수 있는 통계적 검증 기법이야.**  


### 표준편차(Standard Deviation) vs 표준오차(Standard Error)  

**표준편차(standard deviation)**와 **표준오차(standard error)**는 둘 다 데이터의 **흩어짐(변동성)**을 나타내는 지표지만, **의미와 쓰임새가 다르다**  

#### ✅ 표준편차 (SD, σ)  
- **데이터 자체의 분산 정도**를 나타냄  
- 각 관측값이 평균으로부터 얼마나 떨어져 있는지를 측정  
- **"이 데이터는 얼마나 퍼져 있나?"**를 보여줌  
- 예시: 시험 점수의 표준편차이 크면, 학생들 간 실력 차이가 크다는 의미  

#### ✅ 표준오차 (SE, 표기: SE or σ/√n)    
- 표준편차를 바탕으로, **샘플 평균의 정확도**를 나타냄  
- **샘플 평균이 모집단 평균을 얼마나 정확히 추정하는지** 보여줌  
- 샘플이 클수록 SE는 작아짐 → 평균 추정이 더 안정적이라는 뜻  
- 예시: 여러 번 샘플링을 하면 평균값이 조금씩 달라지는데, 그 **평균의 흔들림**을 SE가 나타냄
  
#### ✅ 직관 비교  
| 항목 | 표준편차 (SD) | 표준오차 (SE) |
|------|---------------|---------------|
| 대상 | 데이터의 흩어짐 | 평균의 신뢰도 |
| 크기 | 보통 SE보다 큼 | SD/√n 으로 계산됨 |
| 쓰임 | 데이터 특성 파악 | 신뢰구간, 가설검정 등 추론 |

> 요약: **표준편차는 데이터의 흔들림**, **표준오차는 평균의 흔들림**을 의미  


### 왜 표본이 있는데 표본 분포까지 추정함?  

표본 하나 있으면 평균도 구할 수 있고, 표준편차도 구할 수 있음    
근데 통계에서는 거기서 끝내지 않고 **표본 분포**까지 이야기함    
이유는 다음과 같음  

#### ✅ 표본은 하나지만, 원래는 뽑을 수 있는 경우의 수가 많음  
- 지금 가진 표본은 **모집단에서 하나 뽑힌 결과**일 뿐임    
- 만약 같은 크기의 표본을 **계속 반복해서 뽑는다면**, 그때마다 평균은 조금씩 달라짐    
- 이렇게 반복 샘플링해서 얻는 평균들의 분포가 **표본 분포**임  

#### ✅ 표본 분포를 알아야 하는 이유  
- 우리가 진짜 알고 싶은 건 **모집단의 평균이나 비율 같은 특성**임    
- 근데 모집단 전체는 볼 수 없으니, 일부(표본)만 보고 추측해야 함    
- 이때 "이 표본 평균이 신뢰할 만한가?"를 알려면    
  **평균이 샘플마다 얼마나 흔들리는지**, 즉 **표본 분포의 형태**를 알아야 함    
- 그걸 알아야 **신뢰구간**이나 **가설검정**도 가능해짐  

#### ✅ 결론  
- 표본 하나로 끝내면 그냥 "이 표본에선 이랬다"밖에 못 말함    
- **표본 분포까지 알아야 '이 결과가 우연이냐, 진짜냐'를 말할 수 있음**  


### 왜 중복을 허용(복원추출)해야 하는가?  

#### ✅ 현실: 표본은 하나, 모집단은 없음  
- 부트스트랩은 **모집단이 없는 상황에서 불확실성을 추정**하려고 만들어진 방법임  
- 즉, **지금 가지고 있는 표본 하나만 가지고** 뭔가 판단해야 할 때 쓰는 기법  

#### ✅ 비복원추출은 의미 없음  
- 표본에서 비복원추출하면 → 항상 같은 데이터 구성 (조합만 바뀜)  
- 데이터가 중복 없이 섞인다고 해도, **정보가 추가되지 않음**  
- 1개 표본에서 수십 개 샘플을 뽑는다는 게 불가능함  

#### ✅ 그럼 중복을 허용하면?  
- **표본 안의 데이터들을 랜덤하게 여러 번 뽑아서, 다양성을 인위적으로 만드는 방법**  
- 실제로 **중복이 허용된 표본을 여러 개 만들면**, 통계량(평균, 중앙값 등)이 **조금씩 달라짐**
- 이걸 바탕으로 통계량의 **분포를 근사적으로 만들 수 있음**  
#### ✅ 중복이 "진짜 의미가 있다"
- 예를 들어, 관측값 1번이 부트스트랩 샘플에 2번 나왔다면,
  → 이 데이터가 모델 추정에 **좀 더 큰 영향력을 주는 상황**을 시뮬레이션한 셈
- 즉, 표본을 구성하는 요소들에 **다양한 가중치를 랜덤하게 부여해보는 효과**가 있음

---

### 📌 그래서 결론은?
> 복원추출은 **모집단 없이 추정을 반복할 수 있게 해주는 유일한 방법**  
> 중복을 허용하는 건, **추가 데이터를 얻지 못하는 상황에서 불확실성을 근사적으로 재현하려는 전략**

---

### 타겟 셔플링 (순열 검정, Permutation Test)

#### ✅ "타겟을 섞는다"는 게 무슨 뜻?
- 모델 학습 전에, **타겟값(정답값)을 무작위로 섞는 것**을 의미함
- 입력값(X)은 그대로 두고, 정답값(y)만 랜덤하게 재배열함
- 이 과정을 여러 번 반복하면서 모델 성능을 기록함

#### ✅ 왜 그렇게 함?
- 진짜 타겟과 입력 간에 **관계가 전혀 없다면**, 성능은 우연의 수준이어야 함
- 원래 타겟을 써서 학습한 모델의 성능이,
  이 무작위 타겟들과 비교해서 **훨씬 좋으면 → 실제로 의미 있는 관계가 있다는 증거**가 됨

#### ✅ 예시
- 원래 데이터:  
  X = [a, b, c], y = [1, 0, 1]
- 셔플 1번:  
  X = [a, b, c], y = [0, 1, 1]
- 셔플 2번:  
  X = [a, b, c], y = [1, 1, 0]
- 이렇게 모델 성능을 기록하고, **원래 성능과 비교**해서 유의미한지 판단함 (p-value 계산 등)

---

### 부트스트랩 vs 타겟 셔플링 차이점

| 항목 | 부트스트랩 | 타겟 셔플링 (순열검정) |
|------|------------|----------------------|
| 목적 | 추정치의 **불확실성(신뢰구간)** 추정 | 입력(X)과 타겟(y)의 **관계 유무** 검정 |
| 방법 | 복원추출로 샘플을 여러 번(횟수는 임의로 설정) 뽑음 | 타겟(y)을 랜덤하게 섞음 |
| 고정 요소 | X, y 둘 다 바뀜 (재샘플링) | X는 고정, y만 섞음 |
| 사용 상황 | 신뢰구간, 표준오차, 모델 불안정성 평가 | 가설검정, 통계적 유의성 판단 |
| 예시 질문 | “평균은 얼마나 흔들릴까?” | “이 변수랑 타겟은 관련이 있을까?” |

---

### 핵심 요약

- 🎯 **부트스트랩**: “지금 값이 흔들리는 정도를 알고 싶다” → **불확실성 추정**
- 🎯 **타겟 셔플링**: “이 결과는 우연일까, 진짜일까?” → **관계 유의성 검정**

> 📌 타겟 셔플링은 **"가짜 세상에서 실험해보는 검정"**,  
> 📌 부트스트랩은 **"지금 데이터로 여러 번 시뮬레이션해보는 추정"**

---


### 신뢰수준 (Confidence Level)이란?

#### ✅ 기본 개념
- 신뢰수준은 **“내가 구한 신뢰구간이 진짜 값을 포함하고 있을 확률”을 말함**
- 흔히 말하는 **95% 신뢰수준**은 이렇게 해석함:

> "이런 방식으로 여러 번 샘플을 뽑고 신뢰구간을 만든다면,  
> 그중 **약 95%는 진짜 모집단 값을 포함할 거야**."

---

#### ✅ 일상 예시

> 예를 들어, 눈을 감고 다트 던지기를 100번 함.  
> 매번 다트판 주변에 원을 하나씩 그림 (신뢰구간처럼).  
> 그중 95개는 과녁을 맞춤 (진짜 평균 포함), 5개는 벗어남.

→ 신뢰수준 95%란, **"내가 그린 원이 실제 과녁을 포함할 확률이 95%"**라는 뜻임  
→ 단, **지금 내가 던진 이 한 번의 원이 맞았는지는 알 수 없음!**

---

#### ✅ 헷갈리면 안 되는 점

| 착각 ❌ | 올바른 이해 ✅ |
|--------|-----------------|
| “지금 신뢰구간이 95% 확률로 정답 포함함” | “이런 식으로 하면 95%는 정답 포함하게 됨” |
| “이 구간은 무조건 맞다” | “확률적으로 이 방식은 신뢰할 만하다” |

---

### 요약

> ✔️ 신뢰수준 = 신뢰구간을 **반복해서 만들었을 때**,  
> ✔️ 그 구간들이 **진짜 값을 포함할 확률**

👉 **한 번 만든 구간이 맞았는지 틀렸는지는 알 수 없지만**,  
👉 **우리는 이 방식이 평균적으로 95%쯤은 맞는다고 믿는 것임**

cf) 파이썬  코드   
scipy.stats.probplot 메서드 사용하여 QQ그림을 만듬 


### 카이제곱 통계량 (Chi-Square Statistic)이란?

카이제곱 통계량은 **관측값이 귀무가설 하에서 기대되는 값(기댓값)과 얼마나 차이나는지를 측정하는 통계량**임.

#### ✅ 예를 들어
- 어떤 두 범주형 변수의 독립성을 검정한다고 할 때,
- 귀무가설은 "두 변수는 서로 독립이다"임
- 이 가설이 맞다면, 우리가 관측한 데이터는 **기대값**과 비슷해야 함  

#### ✅ 그런데 실제 데이터는 항상 기대값과 똑같진 않음  
→ 카이제곱 통계량은 이 차이가 **얼마나 큰지(벗어났는지)**를 숫자로 표현함  

#### ✅ 수식 (범주별로 합함)  
> χ² = Σ (관측값 - 기대값)² / 기대값  

#### ✅ 해석  
- 값이 작으면 → 관측값이 기대값과 비슷 → **귀무가설을 지지**  
- 값이 크면 → 관측값이 기대값과 많이 다름 → **귀무가설을 기각할 수 있음**  

---

### 요약 한 줄  

> ✔️ 카이제곱 통계량은 "**기대값에서 얼마나 벗어났는가**"를 측정해서    
> ✔️ **두 범주형 변수의 독립성 여부**를 판단하게 해주는 통계량임.  
  

### F분포란?  

- **F분포**는 "두 개의 분산(흩어짐)을 비교할 때" 쓰는 분포임    
- 항상 **0보다 크고 오른쪽으로 치우친 비대칭 분포**  
- 이름 그대로, F-검정이나 ANOVA에서 **검정통계량**이 따르는 분포임  

> ✔️ 분산 A / 분산 B = F값    
> ✔️ 이 값이 얼마나 큰지를 보고, “두 집단의 분산(또는 평균)이 같은가?”를 판단  
  
---

### ANOVA (분산분석)이란?  

- ANOVA는 **세 집단 이상**의 평균이 서로 같은지 비교하는 방법임    
- 이름은 “Analysis of Variance”지만, 실제로는 **평균 차이**를 보는 검정임  

#### ✅ 기본 아이디어  

> "집단 간 차이(변동)가 집단 내 차이보다 크면 → 평균이 다르다!"  

#### ✅ 분해 구조  
- **총 변동** = **집단 간 변동(Mean 차이)** + **집단 내 변동(개인차 등)**  
- F값 = **집단 간 분산 / 집단 내 분산**  
- 이 F값이 클수록 → 집단 간 평균 차이가 크다고 판단  

---

### 요약  

| 항목 | F분포 | ANOVA (분산분석) |
|------|--------|-------------------|
| 목적 | 분산비를 보기 위한 분포 | 세 집단 이상 평균 비교 |
| 쓰임 | 검정통계량의 분포 | 평균 차이가 유의한지 검정 |
| 관련성 | ANOVA에서 계산한 F값이 따르는 분포 | F분포 기반 검정 |
| 결과 | F값이 크면 귀무가설 기각 | “세 그룹 평균은 다르다” 결론 가능 |

---

### 결론 한 줄

> ✔️ **ANOVA는 여러 그룹의 평균을 비교하는 분석이고**,  
> ✔️ **F분포는 그 분석에서 얻은 통계량이 따르는 분포!**

### 포아송 분포, 지수 분포, 베이불 분포 쉽게 비교하기

#### ✅ 공통점
- 셋 다 **"어떤 사건이 언제, 얼마나 자주 발생하느냐"**와 관련된 확률 분포임
- 특히 **고장, 사고, 고객 도착, 대기 시간** 같은 이벤트 분석에 자주 쓰임

---

### 1. 포아송 분포 (Poisson Distribution)

> ✔️ 단위 시간/공간당 **사건 발생 횟수**를 셈  
> 예: 1시간에 콜센터에 전화가 몇 통 오는가?

- 특징: 정수값(0, 1, 2, ...)에 대한 확률 분포
- 입력: 평균 발생 횟수(λ, 람다)
- 예: 하루 평균 5건 사고가 나면, 오늘 3건 날 확률은?

---

### 2. 지수 분포 (Exponential Distribution)

> ✔️ **두 사건 사이의 시간 간격**을 모델링함  
> 예: 다음 고객이 도착할 때까지 얼마나 걸리는가?

- 특징: 연속형 분포 (시간, 거리 등)
- 포아송 분포의 “대기 시간 버전”
- 입력: 평균 발생률(λ) → 기다릴 시간의 분포로 바뀜
- 예: 사고가 평균 1시간마다 난다면, 다음 사고까지 30분 이내일 확률은?

---

### 3. 베이불 분포 (Weibull Distribution)

> ✔️ 고장이나 수명의 분포를 더 유연하게 모델링  
> 예: 제품이 시간이 지날수록 고장날 확률이 높아진다면?

- 특징: 지수 분포보다 더 다양한 형태 가능
- 입력: **형상(모양) 파라미터 k**, **스케일 파라미터 λ**
  - k = 1 → 지수분포와 같음
  - k > 1 → 시간이 지날수록 고장 확률 증가
  - k < 1 → 시간이 지날수록 고장 확률 감소
- 예: 전구 수명, 기계 부품의 고장 시점 예측

---

### 요약 비교

| 분포 | 무엇을 모델링? | 예시 | 주요 특징 |
|------|------------------|------|-------------|
| 포아송 | 일정 시간당 사건 수 | 1시간에 전화 몇 통 | 정수 개수 셈 |
| 지수 | 사건 사이 시간 | 다음 사고까지 몇 분? | 연속형, 메모리 없음 |
| 베이불 | 수명/고장 시점 | 기계가 언제 고장날까 | 고장률 변화 반영 가능 |

---

> 📌 포아송 = 사건 수  
> 📌 지수 = 다음 사건까지 대기 시간  
> 📌 베이불 = 수명과 고장 패턴까지 고려한 유연한 시간 분포
