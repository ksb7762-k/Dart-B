# CHAPTER 3. 통게적 실험과 유의성 검정 

이 장에서는 전통적인 실험설계에 대해 알아보고 데이터 과학에도 적용되는 몇몇 어려움에 대해 논의함   

또한 통계적 추론에서 자주 인용되는 일부 개념들을 다루고 데이터 과학에서의 의미와 관련성(또는 무관련성)을 설명함  


## 3.2 가설검정 

통계적 가설검정은 연구자가 우연히 일어난 일에 속지 않도록 보호하기 위한 방법으로 개발됨  

용어정리 
- 귀무가설(null hypothesis) : 우연 때문이라는 가설 
- 대립가설(alternative hypothesis) : 귀무가설과 대조 ( 증명하고자 하는 가설 )
- 일원검정(one-way test) : 한 방향으로만 우연히 일어날 확률을 계산하는 가설검정  
- 이원검정 (two-way test) : 양방향으로 우연히 일어날 확률을 계산하는 가설검정 

## 3.2.1 귀무가설  

가설검정은 다음과 같은 논리를 사용함  
'인간은 실제로 우연히 발생한 일이라도 그것이 흔하지 않다면, 그것에 뭔가 의미가 있을 것이라고 해석하는 경황을 가지고 있다. 그리고 실험에서 얻은 그룹간의 차이가 무작위로 얻을 수 있는 합리적인 수준과는 극단적으로 다르다는 증거가 필요하다.' 이 기본 가정을 **귀무가설**이라 함   

## 3.3.1 순열검정  


# ✅ 순열검정(Permutation Test) 총정리

## 1. 정의  
순열검정은 두 집단(또는 그 이상)의 차이가 **우연히 발생한 것인지**를 검증하기 위한 **비모수적(분포 가정 없는)** 통계 기법입니다.  
기본 아이디어는: "귀무가설이 참이라면, 데이터를 무작위로 섞어도 비슷한 결과가 자주 나올 것이다."

---

## 2. 절차 요약

1. **관측된 통계량 계산**  
   - 예: A집단과 B집단의 평균 차이  
   - → 이 값을 기준으로 함 (예: 4.0)

2. **두 집단의 데이터를 합친 뒤, 무작위로 섞는다 (비복원)**  
   - 순서를 바꿔서 새로운 그룹 A와 B를 만든다  
   - 원래와 같은 크기로 나눈다

3. **새 그룹에서 통계량(평균 차이 등)을 계산**  
   - 이 과정을 **수천 번 반복**하여 통계량의 분포를 만든다

4. **관측된 통계량이 이 분포에서 얼마나 극단적인지 확인**  
   - → p-value 계산

---

## 3. 핵심 개념들

- **관측된 통계량**: 데이터를 섞기 전 원래 그룹의 평균 차이 등  
- **순열 통계량**: 데이터를 섞은 후 매번 계산된 평균 차이  
- **p-value**: 귀무가설이 맞다고 가정했을 때, 관측된 차이보다 더 극단적인 결과가 나올 확률  
- **유의수준(α)**: 기각 기준 (보통 0.05)

---

## 4. 해석

- **p-value ≤ α (예: 0.05)**  
  → 관측된 차이는 매우 드문 일 → 귀무가설 기각  
  → → "통계적으로 유의미하다"라고 판단

- **p-value > α**  
  → 관측된 차이는 흔히 일어날 수 있음 → 귀무가설 유지  
  → → "우연일 수 있다"라고 판단

---

# 3.4 통계적 유의성과 P 값

통계적 유의성이란, 어떤 결과가 우연히 발생한 것인지 우연히 발생할 수 없는 극단적인 것인지를 판단하는 방법  

p값 : 귀무가설을 구체화한 기회 모델이 주어졌을 때 관측된 결과와 같이 특이하거나 극단적인 결과를 얻을 확률  



# 3.8 분산분석(ANOVA : analysis of variance)

여러 그룹 간의 통계적으로 유의미한 차이를 검정한는 통계절 절차 

# 🎓 분산분석(ANOVA) 쉽게 이해하기

## 🍰 예시: 제빵사

세 명의 제빵사가 만든 케이크의 **맛 점수**를 비교하고 싶을 때 사용되는 방법이 분산분석.

- A 제빵사의 케이크
- B 제빵사의 케이크
- C 제빵사의 케이크

우리는 "누구의 케이크가 더 맛있는가?"를 알아보기 위해 **평균**을 비교하지만, 단순 평균만으로는 부족함.

## 🔍 핵심: 분산

각 제빵사마다 점수가 들쭉날쭉할 수 있기 때문에, 평균 외에도 **점수의 흩어짐**, 즉 **분산**을 같이 봐야 함.

- 집단 간 분산: 제빵사 평균 간의 차이
- 집단 내 분산: 같은 제빵사 안에서의 개별 차이

이 두 분산의 **비율**을 비교하는 것이 분산분석의 핵심.

## 🔢 F 통계량

분산분석의 결과로 나오는 F 값은 다음과 같은 계산으로 얻음:

$$
F = \frac{\text{집단 간 분산}}{\text{집단 내 분산}}
$$

- F 값이 크면: 집단 간 차이가 명확하다는 신호
- F 값이 작으면: 차이가 없거나 우연일 가능성이 높다는 신호

## 🧠 개념 요약

- 목적: 여러 집단의 평균을 비교
- 기준: 평균 + 분산
- 사용: F 통계량
- 구성: 집단 간, 집단 내
- 결과: 차이의 유의성


# 🧪 이원분산분석 (Two-Way ANOVA)

## ✅ 정의

이원분산분석은 **두 개의 요인**이 종속변수에 미치는 영향을 동시에 분석하는 방법.

## 🥧 예시: 이원분산분석 (Two-Way ANOVA) - 제빵사 × 밀가루

이번에는 단순히 제빵사만 다른 게 아니라, **사용한 밀가루 종류**도 다름.

- 제빵사 A, B, C
- 밀가루 종류: 일반 vs 프리미엄

우리는 알고 싶다:

- **누가 케이크를 더 잘 만드는가?** (제빵사 효과)
- **어떤 밀가루가 더 맛있는가?** (밀가루 효과)
- **제빵사와 밀가루의 조합이 맛에 영향을 주는가?** (상호작용 효과)

→ 이럴 때 사용하는 것이 **이원분산분석 (Two-Way ANOVA)**

---

### 🔍 핵심: 요인이 두 개

- 요인 1: 제빵사
- 요인 2: 밀가루 종류
- 검정 목적: 각 요인의 **주효과** + 둘의 **상호작용 효과**

---

### 💥 상호작용(interaction)의 개념

"제빵사 A는 프리미엄 밀가루일 때만 점수가 높고,  
B는 밀가루 종류에 상관없고,  
C는 오히려 일반 밀가루일 때 더 좋다?"

→ 이런 패턴이 **상호작용 효과**이며,  
이원분산분석에서는 이를 **별도로 검정**함

---

### 🔢 F 통계량 × 3개

이원분산분석에서는 다음 3개의 F 통계량을 계산함:

1. 제빵사 효과 (요인 A의 주효과)
2. 밀가루 효과 (요인 B의 주효과)
3. 상호작용 효과 (A × B의 교호작용)

각 F 값은 다음과 같이 계산됨:

$$
F = \frac{\text{요인 또는 상호작용의 분산}}{\text{오차 분산}}
$$

F 값이 클수록 해당 요인이 결과에 큰 영향을 줌

---


### ✅ 오차 분산 (Mean Square Error)

$$
MS_E = \frac{SS_E}{df_E}
$$

- \( SS_E \): 오차 제곱합 (Sum of Squares for Error)  
- \( df_E \): 오차 자유도 (Degrees of Freedom for Error)  
- 의미: 각 처리 조합 내에서 개별 관측치가 **해당 그룹 평균에서 얼마나 떨어져 있는지**를 나타내는 분산

---

### ✅ 상호작용 분산 (Mean Square for Interaction)

$$
MS_{AB} = \frac{SS_{AB}}{df_{AB}}
$$

-  \( SS_{AB} \) : 상호작용 제곱합 (Sum of Squares for Interaction)  
- \( df_{AB} = (a - 1)(b - 1) \): 상호작용 자유도 (요인 A 수준 수 = \(a\), 요인 B 수준 수 = \(b\))  
- 의미: 요인 A의 효과가 요인 B의 수준에 따라 **달라지는 정도**, 즉 **조합이 결과에 주는 고유한 영향**

---

### ✅ 상호작용 제곱합 \( SS_{AB} \) 계산 개요

집단별 평균을 기준으로 다음을 계산합니다:

$$
SS_{AB} = \sum_{i=1}^{a} \sum_{j=1}^{b} n_{ij} \left( \bar{Y}_{ij} - \bar{Y}_{i.} - \bar{Y}_{.j} + \bar{Y}_{..} \right)^2
$$

- \( \bar{Y}_{ij} \): 제빵사 \(i\)와 밀가루 \(j\) 조합의 평균
- \( \bar{Y}_{i.} \): 제빵사 \(i\)의 전체 평균
- \( \bar{Y}_{.j} \): 밀가루 \(j\)의 전체 평균
- \( \bar{Y}_{..} \): 전체 평균
- \( n_{ij} \): 해당 조합의 표본 수

→ 이 수식은 **상호작용이 없을 때 기대되는 평균**과 **실제 평균의 차이**를 계산하는 구조

---

## ✅ 정리

- **오차 분산 \( MS_E \)**: 각 조합 내 관측값들의 흩어짐 (잔차)
- **상호작용 분산 \( MS_{AB} \)**: 조합이 주는 고유한 영향의 크기
- **F 값**이 클수록 → 조합 또는 요인이 결과에 **의미 있는 영향**을 준다는 뜻

### ✅ 카이제곱 검정의 종류

#### 1. 적합도 검정 (Goodness-of-Fit)
한 범주형 변수의 분포가 이론적 분포와 적합한지 검정함  
예: 요일별 방문자가 균등한지 검정함  
자유도(df) = 범주 수 – 1로 계산함  

#### 2. 독립성 검정 (Test of Independence)
두 범주형 변수 간의 관련성 검정에 사용됨  
예: 성별과 구매 여부의 독립성 검정  
자유도(df) = (행 개수 – 1) × (열 개수 – 1)로 계산함  

---

### ✅ 기대값이란?
실제로 기대되는 평균적 수치 의미함  
적합도 검정에서는 전체 합을 범주 수로 나눈 값이 기대값임  
독립성 검정에서는 다음과 같이 계산함  
$$
E = \frac{(\text{행의 합}) \times (\text{열의 합})}{\text{전체 합}}
$$

---

### ✅ 기댓값과 평균은 같은가?
같을 수도 있고 다를 수도 있음  
요일별 방문처럼 분포가 균등하면 평균과 같아짐  
로또처럼 확률이 불균형한 경우 평균과 달라짐  

---

### ✅ 분포(자유도)가 검정 종류에 따라 다른 이유
적합도 검정은 단일 변수 기준이라 단순함 → 자유도 = 범주 수 – 1  
독립성 검정은 표의 구조를 따름 → 자유도 = (행 – 1)(열 – 1)  
자유도가 달라지면 카이제곱 분포 모양도 달라짐  

---

### ✅ 카이제곱 분포표는 주어지나?
시험이나 과제에서는 보통 분포표 제공됨  
실무나 코드에서는 p-value로 직접 계산함  

---

## 📊 예시 1: 요일별 방문 분포 검정 (적합도 검정)

- 질문: 요일에 따라 방문자 수 차이 존재하는지 검정함  
- 관측값: [130, 120, 115, 140, 125, 180, 190]  
- 기대값: 총합 1000 → $$ \frac{1000}{7} \approx 142.86 $$  

- 귀무가설 $$H_0$$: 방문은 요일과 무관함  
- 대립가설 $$H_1$$: 요일에 따라 차이 있음  
- 각 요일에 대해 다음 계산 수행  
$$
\chi^2 = \sum \frac{(O - E)^2}{E}
$$  
- 자유도 df = 7 – 1 = 6  
- 계산 결과 $$\chi^2 = 37.75$$  
- 유의수준 0.05에서 임계값은 12.59  
- $$37.75 > 12.59$$ → 귀무가설 기각  
- p-value ≈ 0.00000126 → 매우 작음  
- 결론: 요일별 방문은 통계적으로 차이 있음  

---

## 📊 예시 2: 성별과 구매 여부 독립성 검정 (독립성 검정)

- 질문: 성별과 구매 여부 간 관련성 존재 여부 확인함  

- 데이터표:
| 성별 | 구매함 | 구매 안 함 | 합계 |
|------|--------|------------|------|
| 남성 | 40     | 60         | 100  |
| 여성 | 70     | 30         | 100  |
| 합계 | 110    | 90         | 200  |

- 기대값 계산:
  - 남성&구매함:  
    $$
    \frac{100 \times 110}{200} = 55
    $$
  - 기타 셀도 동일 방식으로 계산함  

- 각 셀에 대해 다음 계산 수행:
$$
\chi^2 = \sum \frac{(O - E)^2}{E}
$$  
- 계산 결과 $$\chi^2 = 18.18$$  
- 자유도 = (2 – 1)(2 – 1) = 1  
- 임계값 3.84보다 큼 → 귀무가설 기각  
- 결론: 성별과 구매 여부는 통계적으로 유의한 관련성 존재함  

## 📘 검정력, 표본 크기, p-value, 유의수준의 관계 정리

### ✅ 개념 요약

- **p-value**: 귀무가설이 참일 때 관측된 통계량 이상의 값이 나올 확률 의미함  
- **유의수준(α)**: "이 정도 확률보다 낮으면 우연이라 보기 어렵다"는 기준선임  
- **검정력(power)**: 대립가설이 참일 때, 귀무가설을 기각할 수 있는 확률 의미함  
- **표본 크기(n)**: 수집한 데이터의 양을 의미하며, 모든 요소에 영향을 줌  

---

### ✅ 관계 정리

| 요소         | 영향을 주는 대상                              |
|--------------|-----------------------------------------------|
| 표본 크기 ↑  | → 검정력 ↑, p-value ↓                         |
| 효과 크기 ↑  | → 검정력 ↑, p-value ↓                         |
| 유의수준 ↑   | → 검정력 ↑ (기각 기준이 느슨해짐)             |
| 검정력 ↑     | → 실제 차이가 있을 때 기각 확률 ↑             |
| 검정력 ↓     | → 효과가 있어도 기각 못 할 가능성 ↑ (2종 오류 ↑) |

---

### ✅ 시나리오 예시

- **표본이 작고 효과도 작음** → p-value는 커지고 검정력은 낮아짐  
- **표본이 충분하고 효과도 큼** → p-value는 작아지고 검정력은 높아짐  
- **유의수준을 0.01 → 0.05로 높이면** → 기각 기준이 낮아져 검정력은 올라감  
- 단, 유의수준을 높이면 **1종 오류(잘못된 기각)** 확률도 함께 올라감  

---

### ✅ 정리된 수식 관점 요약

- 검정력은 다음 네 요소에 의해 결정됨:
  $$
  \text{검정력} = f(\text{효과 크기}, \text{표본 수}, \alpha, \text{검정 방법})
  $$
- p-value는 고정된 샘플에서 계산된 확률값이고,  
  유의수준은 사전에 정한 임계값이며,  
  검정력은 **실제 효과가 있을 때 그걸 잡아낼 능력**임  

---

### ✅ 단어로 요약

- p-value는 관측된 극단성의 확률임  
- 유의수준은 그 p-value를 판단할 기준임  
- 검정력은 진짜 효과가 있을 때 그걸 찾아낼 힘임  
- 표본 크기는 모든 요소에 영향을 주는 핵심 요인임  


**p-value는 "우연이 아닐 확률"이 아니라,
"우연이라고 가정했을 때, 지금처럼 극단적인 결과가 나올 확률"**임.